{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNc0wW+qfr79WnuyzY3HfXa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"w3yEcXAW8XPY"},"outputs":[],"source":["\"\"\"Useage Gemini API for RAG\"\"\"\n","# Install required packages\n","!pip install sentence-transformers faiss-cpu google-generativeai\n","!pip install PyMuPDF  # For PDF processing\n","\n","import fitz  # PyMuPDF for PDF extraction\n","import json\n","import os\n","import numpy as np\n","import faiss\n","from sentence_transformers import SentenceTransformer\n","import google.generativeai as genai\n","from google.colab import userdata\n","api_key = userdata.get(\"api_key\") or \"YOUR_GEMINI_API_KEY\"\n","genai.configure(api_key=api_key)"]},{"cell_type":"code","source":["# ------------------------------\n","# 1. PDF Text Extraction & Preprocessing\n","# ------------------------------\n","\n","def extract_pdf_text(pdf_path):\n","    \"\"\"Extract text from PDF file\"\"\"\n","    try:\n","        doc = fitz.open(pdf_path)\n","        text = \"\"\n","        for page in doc:\n","            text += page.get_text()\n","        doc.close()\n","        return text\n","    except Exception as e:\n","        print(f\"Error extracting text from {pdf_path}: {e}\")\n","        return \"\"\n","\n","def clean_text(text):\n","    \"\"\"Clean and preprocess text\"\"\"\n","    # Remove excessive whitespace and clean up text\n","    lines = text.split('\\n')\n","    cleaned_lines = []\n","\n","    for line in lines:\n","        line = line.strip()\n","        if len(line) > 10:  # Skip very short lines (likely headers/footers)\n","            cleaned_lines.append(line)\n","\n","    return ' '.join(cleaned_lines)\n","\n","def chunk_text(text, chunk_size=500, overlap=50):\n","    \"\"\"Create overlapping chunks for better context retention\"\"\"\n","    words = text.split()\n","    chunks = []\n","\n","    for i in range(0, len(words), chunk_size - overlap):\n","        chunk = \" \".join(words[i:i + chunk_size])\n","        if len(chunk.strip()) > 50:  # Only keep substantial chunks\n","            chunks.append(chunk)\n","\n","    return chunks"],"metadata":{"id":"nxzvZ4xE8ggB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------\n","# 2. Build Legal Corpus\n","# ------------------------------\n","\n","def build_legal_corpus():\n","    \"\"\"Build comprehensive legal corpus from PDFs and Q&A data\"\"\"\n","\n","    # PDF files (update paths as needed)\n","    pdf_files = {\n","        \"CPA2019\": \"/content/CPA2019.pdf\",\n","        \"MVA\": \"/content/MVA.pdf\",\n","        \"RTI\": \"/content/rti-act.pdf\"\n","    }\n","\n","    corpus = []\n","\n","    # Process PDF files\n","    print(\"Processing PDF files...\")\n","    for label, path in pdf_files.items():\n","        if os.path.exists(path):\n","            print(f\"Processing {label}...\")\n","            full_text = extract_pdf_text(path)\n","            cleaned_text = clean_text(full_text)\n","            chunks = chunk_text(cleaned_text, chunk_size=500, overlap=50)\n","\n","            for i, chunk in enumerate(chunks):\n","                corpus.append({\n","                    \"text\": chunk,\n","                    \"metadata\": {\n","                        \"source\": label,\n","                        \"chunk_id\": i,\n","                        \"doc_type\": \"legislation\"\n","                    }\n","                })\n","            print(f\"Added {len(chunks)} chunks from {label}\")\n","        else:\n","            print(f\"Warning: {path} not found\")\n","\n","    # Process Q&A dataset\n","    qa_file = \"/content/IndicLegalQA Dataset_10K_Revised.json\"\n","    if os.path.exists(qa_file):\n","        print(\"Processing Q&A dataset...\")\n","        try:\n","            with open(qa_file, \"r\", encoding=\"utf-8\") as f:\n","                qa_data = json.load(f)\n","\n","            for i, qa in enumerate(qa_data):\n","                corpus.append({\n","                    \"text\": f\"Question: {qa['question']} Answer: {qa['answer']}\",\n","                    \"metadata\": {\n","                        \"source\": \"IndicLegalQA\",\n","                        \"case_name\": qa.get(\"case_name\", \"Unknown\"),\n","                        \"judgement_date\": qa.get(\"judgement_date\", \"\"),\n","                        \"doc_type\": \"qa_pair\",\n","                        \"qa_id\": i\n","                    }\n","                })\n","            print(f\"Added {len(qa_data)} Q&A pairs\")\n","\n","        except Exception as e:\n","            print(f\"Error loading Q&A data: {e}\")\n","    else:\n","        print(f\"Warning: {qa_file} not found\")\n","\n","    return corpus\n","\n","# Build the corpus\n","corpus = build_legal_corpus()\n","print(f\"\\nLegal corpus created with {len(corpus)} entries.\")\n"],"metadata":{"id":"bYJtLSEa8kDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------\n","# 3. Create Vector Embeddings & FAISS Index\n","# ------------------------------\n","\n","class LegalRAGSystem:\n","    def __init__(self, corpus):\n","        self.corpus = corpus\n","        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')  # Fast, good embeddings\n","        self.index = None\n","        self.gemini_model = genai.GenerativeModel('gemini-pro')\n","\n","    def build_index(self):\n","        \"\"\"Build FAISS vector index from corpus\"\"\"\n","        print(\"Creating embeddings...\")\n","        texts = [item[\"text\"] for item in self.corpus]\n","\n","        # Create embeddings in batches to avoid memory issues\n","        batch_size = 100\n","        embeddings = []\n","\n","        for i in range(0, len(texts), batch_size):\n","            batch = texts[i:i + batch_size]\n","            batch_embeddings = self.embedder.encode(batch)\n","            embeddings.append(batch_embeddings)\n","            print(f\"Processed {min(i + batch_size, len(texts))}/{len(texts)} texts\")\n","\n","        # Combine all embeddings\n","        embeddings = np.vstack(embeddings)\n","\n","        # Build FAISS index\n","        print(\"Building FAISS index...\")\n","        dimension = embeddings.shape[1]\n","        self.index = faiss.IndexFlatIP(dimension)  # Inner product for similarity\n","\n","        # Normalize embeddings for cosine similarity\n","        faiss.normalize_L2(embeddings)\n","        self.index.add(embeddings.astype('float32'))\n","\n","        print(f\"Index built with {self.index.ntotal} vectors\")\n","\n","    def search(self, query, top_k=5):\n","        \"\"\"Search for relevant documents\"\"\"\n","        query_embedding = self.embedder.encode([query])\n","        faiss.normalize_L2(query_embedding)\n","\n","        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n","\n","        results = []\n","        for score, idx in zip(scores[0], indices[0]):\n","            if idx < len(self.corpus):\n","                results.append({\n","                    \"text\": self.corpus[idx][\"text\"],\n","                    \"metadata\": self.corpus[idx][\"metadata\"],\n","                    \"similarity_score\": float(score)\n","                })\n","\n","        return results\n","\n","    def generate_answer(self, query, search_results):\n","        \"\"\"Generate answer using Gemini based on search results\"\"\"\n","\n","        # Prepare context from search results\n","        context = \"\\n\\n\".join([\n","            f\"Source: {result['metadata']['source']}\\n{result['text']}\"\n","            for result in search_results\n","        ])\n","\n","        # Create prompt for Gemini\n","        prompt = f\"\"\"You are a legal expert AI assistant. Use the following legal documents and information to answer the user's question accurately and comprehensively.\n","\n","CONTEXT FROM LEGAL DOCUMENTS:\n","{context}\n","\n","USER QUESTION: {query}\n","\n","INSTRUCTIONS:\n","1. Provide a clear, accurate answer based on the provided legal context\n","2. Cite specific sources when possible (CPA2019, MVA, RTI, or case references)\n","3. If the context doesn't contain enough information, clearly state this\n","4. Use professional legal language but make it understandable\n","5. Structure your response with clear points when appropriate\n","\n","ANSWER:\"\"\"\n","\n","        try:\n","            response = self.gemini_model.generate_content(prompt)\n","            return response.text\n","        except Exception as e:\n","            return f\"Error generating response: {e}\"\n","\n","    def query(self, question, top_k=5):\n","        \"\"\"Main query function - search + generate\"\"\"\n","        print(f\"Searching for: {question}\")\n","\n","        # Search for relevant documents\n","        search_results = self.search(question, top_k=top_k)\n","\n","        print(f\"Found {len(search_results)} relevant documents\")\n","        for i, result in enumerate(search_results):\n","            print(f\"  {i+1}. Source: {result['metadata']['source']} (Score: {result['similarity_score']:.3f})\")\n","\n","        # Generate answer using Gemini\n","        answer = self.generate_answer(question, search_results)\n","\n","        return {\n","            \"question\": question,\n","            \"answer\": answer,\n","            \"sources\": search_results\n","        }\n","\n","    def save_index(self, index_path=\"legal_index.faiss\", metadata_path=\"legal_metadata.json\"):\n","        \"\"\"Save index and metadata for later use\"\"\"\n","        if self.index:\n","            faiss.write_index(self.index, index_path)\n","            with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n","                json.dump(self.corpus, f, ensure_ascii=False, indent=2)\n","            print(f\"Index saved to {index_path}, metadata to {metadata_path}\")\n","\n","    def load_index(self, index_path=\"legal_index.faiss\", metadata_path=\"legal_metadata.json\"):\n","        \"\"\"Load pre-built index and metadata\"\"\"\n","        if os.path.exists(index_path) and os.path.exists(metadata_path):\n","            self.index = faiss.read_index(index_path)\n","            with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n","                self.corpus = json.load(f)\n","            print(f\"Index loaded from {index_path}\")\n","            return True\n","        return False\n"],"metadata":{"id":"UfYa5zeE8nqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------\n","# 4. Initialize and Build RAG System\n","# ------------------------------\n","\n","# Create RAG system\n","rag_system = LegalRAGSystem(corpus)\n","\n","# Try to load existing index, otherwise build new one\n","if not rag_system.load_index():\n","    print(\"Building new index...\")\n","    rag_system.build_index()\n","    rag_system.save_index()\n","else:\n","    print(\"Loaded existing index\")\n"],"metadata":{"id":"lDUqau9F8unL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------\n","# 5. Test the System\n","# ------------------------------\n","\n","def test_legal_rag():\n","    \"\"\"Test the RAG system with sample questions\"\"\"\n","\n","    test_questions = [\n","        \"What are the consumer rights under CPA 2019?\",\n","        \"What is the procedure for filing RTI application?\",\n","        \"What are the penalties under Motor Vehicle Act?\",\n","        \"How to file a consumer complaint?\",\n","        \"What information can be sought under RTI Act?\"\n","    ]\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"TESTING LEGAL RAG SYSTEM\")\n","    print(\"=\"*80)\n","\n","    for i, question in enumerate(test_questions, 1):\n","        print(f\"\\n--- TEST {i} ---\")\n","        result = rag_system.query(question, top_k=3)\n","\n","        print(f\"Question: {result['question']}\")\n","        print(f\"Answer: {result['answer']}\")\n","        print(\"\\nTop Sources:\")\n","        for j, source in enumerate(result['sources'], 1):\n","            print(f\"  {j}. {source['metadata']['source']} (Score: {source['similarity_score']:.3f})\")\n","        print(\"-\" * 60)\n","\n","# Run tests\n","test_legal_rag()\n"],"metadata":{"id":"6N70Ancw8xx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" ------------------------------\n","# 6. Interactive Query Function\n","# ------------------------------\n","\n","def interactive_legal_assistant():\n","    \"\"\"Interactive legal assistant\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"LEGAL AI ASSISTANT (Powered by Gemini)\")\n","    print(\"=\"*60)\n","    print(\"Ask me any legal questions about CPA 2019, MVA, RTI Act, or general legal queries!\")\n","    print(\"Type 'exit' to quit\")\n","    print(\"-\" * 60)\n","\n","    while True:\n","        try:\n","            question = input(\"\\n🏛️  Your question: \").strip()\n","\n","            if question.lower() in ['exit', 'quit', 'bye']:\n","                print(\"Thank you for using Legal AI Assistant!\")\n","                break\n","\n","            if not question:\n","                print(\"Please enter a question.\")\n","                continue\n","\n","            print(\"\\n🔍 Searching legal database...\")\n","            result = rag_system.query(question, top_k=3)\n","\n","            print(f\"\\n📖 Answer:\")\n","            print(result['answer'])\n","\n","            print(f\"\\n📚 Sources consulted:\")\n","            for i, source in enumerate(result['sources'], 1):\n","                source_name = source['metadata']['source']\n","                score = source['similarity_score']\n","                print(f\"  {i}. {source_name} (Relevance: {score:.1%})\")\n","\n","        except KeyboardInterrupt:\n","            print(\"\\n\\nGoodbye!\")\n","            break\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","\n","# Start interactive assistant\n","interactive_legal_assistant()"],"metadata":{"id":"3eSRbhDp8yrK"},"execution_count":null,"outputs":[]}]}